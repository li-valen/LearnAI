<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Object Detection with MobileNet SSD</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.12.0"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
</head>
<body>
    <h1>Object Detection with MobileNet SSD</h1>
    <video id="video" width="640" height="480" autoplay></video>
    <canvas id="canvas" width="640" height="480"></canvas>
    <button onclick="startObjectDetection()">Start Object Detection</button>
    <button onclick="stopObjectDetection()">Stop Object Detection</button>

    <script>
        let videoElement;
        let canvasElement;
        let context;
        let model;
        let isObjectDetectionRunning = false;

        async function startObjectDetection() {
            if (isObjectDetectionRunning) return;

            videoElement = document.getElementById('video');
            canvasElement = document.getElementById('canvas');
            context = canvasElement.getContext('2d');

            model = await cocoSsd.load();

            navigator.mediaDevices.getUserMedia({ video: true })
                .then(function(stream) {
                    videoElement.srcObject = stream;
                    videoElement.onloadedmetadata = detectObjects;
                })
                .catch(function(err) {
                    console.log("Error accessing webcam: " + err);
                });

            isObjectDetectionRunning = true;
        }

        function stopObjectDetection() {
            if (!isObjectDetectionRunning) return;

            const stream = videoElement.srcObject;
            const tracks = stream.getTracks();
            tracks.forEach(track => track.stop());

            isObjectDetectionRunning = false;
        }

        async function detectObjects() {
            if (!isObjectDetectionRunning) return;

            context.drawImage(videoElement, 0, 0, canvasElement.width, canvasElement.height);

            const predictions = await model.detect(videoElement);

            for (let i = 0; i < predictions.length; i++) {
                const [x, y, width, height] = predictions[i].bbox;
                const label = predictions[i].class;
                const score = predictions[i].score;

                // Draw bounding box
                context.beginPath();
                context.rect(x, y, width, height);
                context.lineWidth = 2;
                context.strokeStyle = 'red';
                context.fillStyle = 'red';
                context.stroke();
                context.font = '16px Arial';
                context.fillText(`${label} (${(score * 100).toFixed(2)}%)`, x, y - 5);
            }

            requestAnimationFrame(detectObjects);
        }
    </script>
</body>
</html>
